{"meta":{"title":"Ferrilata's blog","subtitle":"","description":"","author":"Ferrilata","url":"119.3.128.89","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2020-08-20T10:35:02.501Z","updated":"2020-08-19T13:15:30.000Z","comments":false,"path":"/404.html","permalink":"119.3.128.89/404.html","excerpt":"","text":""},{"title":"关于","date":"2020-08-20T10:35:02.501Z","updated":"2020-08-20T10:06:43.922Z","comments":false,"path":"about/index.html","permalink":"119.3.128.89/about/index.html","excerpt":"","text":"BUPT"},{"title":"分类","date":"2020-08-20T10:35:02.501Z","updated":"2020-08-20T09:01:25.000Z","comments":false,"path":"categories/index.html","permalink":"119.3.128.89/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-08-20T10:35:02.501Z","updated":"2020-08-19T13:15:30.000Z","comments":false,"path":"tags/index.html","permalink":"119.3.128.89/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"利用SQL函数批量插入测试数据","slug":"利用SQL函数批量插入测试数据","date":"2020-08-20T09:47:55.890Z","updated":"2020-08-20T10:34:24.812Z","comments":true,"path":"2020/08/20/利用SQL函数批量插入测试数据/","link":"","permalink":"119.3.128.89/2020/08/20/%E5%88%A9%E7%94%A8SQL%E5%87%BD%E6%95%B0%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE/","excerpt":"","text":"学习过程中需要创建一张含有批量数据的测试表，可以使用高级语言插入，但感觉比较麻烦，搜了搜可以采用SQL函数，直接在命令行页面批量插入。0. 数据库名为studytest，表名为student： 12345678910CREATE DATABASE studytest;use studytest;CREATE TABLE `student` ( `s_id` int(11) NOT NULL AUTO_INCREMENT, `s_name` varchar(100) DEFAULT NULL, `s_age` int(11) DEFAULT NULL, `s_phone` varchar(30) DEFAULT NULL, PRIMARY KEY (`s_id`), KEY `s_name` (`s_name`)) ENGINE=InnoDB, CHARSET=utf8; SQL函数： 1234567891011121314-- 定义分界符DELIMITER $$CREATE PROCEDURE insert_student(IN START INT(10),IN max_num INT(10))BEGIN DECLARE i INT DEFAULT START; -- 关闭自动提交 SET autocommit=0; REPEAT SET i=i+1; INSERT INTO student (s_id,s_name,s_age,s_phone) VALUES (i,CONCAT(&#x27;name_&#x27;,i),MOD(i,70),CONCAT(&#x27;phone_&#x27;,i)); UNTIL i=max_num END REPEAT; COMMIT;END $$ 调用该函数： 123-- 先把分隔符换回来，方便操作。不换回来也行，就是以后的；都要写成 $$DELIMITER ; $$CALL insert_student(0,100000); 恢复自动提交：MySQL默认开启自动提交。除非显式地开始一个事务，否则每个查询都被当做一个单独的事务自动执行。 1SET autocommit=1; 查看autocommit状态：命令：show variables like ‘autocommit’;结果： PS：也可以直接利用SQL工具，如Navicat创建函数，完成批量插入。详见：mysql使用函数批量插入数据 完成后的student表： 参考博客：mysql使用存储过程&amp;函数实现批量插入MySQL用存储过程与函数批量插入数据MySQL事务autocommit自动提交","categories":[{"name":"SQL","slug":"SQL","permalink":"119.3.128.89/categories/SQL/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"119.3.128.89/tags/SQL/"}]},{"title":"LeetCode-146--LRU缓存机制","slug":"LeetCode-146--LRU缓存机制","date":"2020-08-20T09:46:14.015Z","updated":"2020-08-20T09:57:23.298Z","comments":true,"path":"2020/08/20/LeetCode-146--LRU缓存机制/","link":"","permalink":"119.3.128.89/2020/08/20/LeetCode-146--LRU%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/","excerpt":"","text":"题目描述:运用你所掌握的数据结构，设计和实现一个 LRU (最近最少使用) 缓存机制。它应该支持以下操作： 获取数据 get 和 写入数据 put 。 获取数据 get(key) - 如果关键字 (key) 存在于缓存中，则获取关键字的值（总是正数），否则返回 -1。写入数据 put(key, value) - 如果关键字已经存在，则变更其数据值；如果关键字不存在，则插入该组「关键字/值」。当缓存容量达到上限时，它应该在写入新数据之前删除最久未使用的数据值，从而为新的数据值留出空间。请在 O(1) 时间复杂度内完成这两种操作。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/lru-cache著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 解答：方法一：（来自LeetCode官方题解）使用自带的LinkedHashMap，可以直接模拟LRU。LinkedHashMap的数据结构是在HashMap的基础上，为每个HashMap节点都增加了两个属性before、after，并用双链表把每个节点连接起来，before、after分别代表某元素在双链表的前一个、后一个元素。详细可参考Java集合详解5：深入理解LinkedHashMap和LRU缓存 1234567891011121314151617181920212223242526272829303132333435//LinkedHashMap的双向链表实现LRU，最后节点为常访问的，头部的节点是最近最久未使用的import java.util.LinkedHashMap;class LRUCache extends LinkedHashMap &#123; int capacity; LRUCache(int capacity) &#123; // 需要使用LinkedHashMap中accessOrder=true的构造函数 // LinkedHashMap(int initialCapacity,float loadFactor,boolean accessOrder) // 顺便说个知识点，HashMap初始化并不会分配内存，分配是在第一次put元素后 super(capacity, 0.75F, true); this.capacity = capacity; &#125; public int get(int key) &#123; // 这个函数是getkey，如果取不到，则返回defaulValue，即第二个参数 return super.getOrDefault(key, -1); &#125; public void put(int key, int value) &#123; // 直接继承HashMap的put方法，如果accessOrder=true，则会把刚访问的节点或者新添加的节点安排到双链表末尾 super.put(key, value); &#125; @Override protected boolean removeEldestEntry(Map.Entry&lt;Integer, Integer&gt; eldest) &#123; // LinkedHashMap继承HashMap，二者的removeEldestEntry均return false，表示不删除最近最久未使用节点 // 需要重写，这里的逻辑是当元素个数大于初始容量时 // // HashMap的threshold修饰级别是default，除了HashMap的实例外，HashMap所在package的其他类也可以访问， // 但是除此之外其他都不能访问。因此，这里发生删除元素时，size&gt;16，实际的capacity&gt;24(16/0.75=24) return size() &gt; capacity; &#125;&#125; 方法二：哈希表+双向链表方式构造LRU。HashMap用来定位某元素在节点中的位置，映射关系是&lt;Key, ListNode&gt;，(HashMap).get(key)直接拿到节点。双向链表模拟LRU缓存，头部位置代表最近访问过的，尾部表示最久未使用的。原因：访问过的都往头部转移，那些不常访问的元素就会越来越往后移动。 这个哪一端是刚刚访问的，随你心情定义，你也可以定义尾部就是刚刚访问的，而头部是最久未使用的。get(int key)的逻辑：寻找某元素时，找不到就返回-1，找得到就返回value，并把该元素移动到头部，代表最近访问了，久而久之，尾部就会使最久未使用的元素。put(int key, int value)的逻辑是，如果不是新元素，就更新该元素value（同时意味着该元素要移动到开头,可以利用get(key)判断是否是新元素，若元素已存在就会移动到开头，然后更新开头元素value）；如果是新元素，容量足够就加到头部，代表刚刚访问；容量不够，就得移除尾部节点，再在头部节点添加元素。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.Stack;class ListNode &#123; int key; int value; ListNode before; ListNode after; ListNode(int key, int value) &#123; this.key = key; this.value = value; &#125;&#125;class LRUCache &#123; int capacity; // head和tail操作来自LinkedHashMap思想，好处是可以避免好多节点判空操作，比较方便。 // 牺牲两个节点空间换来操作方便，可以作为编程技巧。 ListNode head; ListNode tail; Map&lt;Integer, ListNode&gt; map; LRUCache(int capacity) &#123; this.capacity = capacity; head = new ListNode(-1, -1); tail = new ListNode(-1, -1); head.after = tail; tail.before = head; map = new HashMap&lt;&gt;(); &#125; // get的逻辑是：找不到返回-1，找得到就返回value，并把该元素移动到头部，代表最近访问了，久而久之，尾部就会使最久未使用的元素 public synchronized int get(int key) &#123; if (capacity == 0) return -1; ListNode vn = map.get(key); // 找不到元素 if (vn == null) return -1; // 找到元素，无论它在哪，肯定有前后节点，最不济是head和tail，所以前后节点一定不为空 // 如果vn是头一个节点，不必操作，直接返回 if (vn.before == head) return vn.value; // 否则，在vn原来的地方移除vn removeNode(vn); // 移动到开头 addToHead(vn); return vn.value; &#125; // put的逻辑是，如果不是新元素，就更新该元素value(同时意味着该元素要移动到开头,可以利用get判断是否是新元素，若元素已存在会移动到开头)； // 如果是新元素，容量够就加到头部，代表刚刚访问；容量不够，就得移除尾部节点，再在头部节点添加元素 public synchronized void put(int key, int value) &#123; if (capacity == 0) return; // 增添就意味着可能要移除元素 int v = get(key); // 并非新元素，更新 if (v != -1) &#123; head.after.value = value; return; &#125; ListNode newNode = new ListNode(key, value); /* 这个注释掉的内容是添加新节点的另一个方式 // 超容量就删除尾部节点 if (map.size() + 1 &gt; capacity) &#123; map.remove(tail.before.key); removeNode(tail.before); &#125; // 添加节点到头部 map.put(key, newNode); addToHead(newNode); */ // 多一个元素不超容量，可以直接压入头部 if (map.size() + 1 &lt;= capacity) &#123; addToHead(newNode); map.put(key, newNode); return; &#125; // 超容量，要去除最后一个最久未使用,并在最前面加入新元素 // tail.before=head是为了防止容量为0，当然可以直接在开头预防 // if (tail.before = head) // return; // 对应map要删除重添加 map.remove(tail.before.key); map.put(key, newNode); removeNode(tail.before); addToHead(newNode); &#125; private synchronized void removeNode(ListNode node) &#123; node.before.after = node.after; node.after.before = node.before; &#125; private synchronized void addToHead(ListNode vn) &#123; ListNode first = head.after; head.after = vn; vn.before = head; vn.after = first; first.before = vn; &#125;&#125; 完毕。LRU缓存这道题常见于字节跳动的面试题，这里同时分享一个字节跳动面试常考算法题，来自LeetCode.LeetCode探索之字节跳动","categories":[{"name":"算法题目","slug":"算法题目","permalink":"119.3.128.89/categories/%E7%AE%97%E6%B3%95%E9%A2%98%E7%9B%AE/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"119.3.128.89/tags/LeetCode/"}]},{"title":"服务器搭建Hexo","slug":"服务器搭建Hexo","date":"2020-08-20T08:45:02.534Z","updated":"2020-08-20T09:57:24.323Z","comments":true,"path":"2020/08/20/服务器搭建Hexo/","link":"","permalink":"119.3.128.89/2020/08/20/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAHexo/","excerpt":"","text":"买了服务器一直没用，先搞个博客吧，因为发现简书的发布博客好像有一日上限，不舒服。 首先看个服务器搭建Hexo的整体架构图，非常好，有利于理解接下来的步骤。来自博客：如何在服务器上搭建hexo博客 步骤大纲：一、 本地计算机配置Hexo程序二、服务端配置网站根目录、Git裸仓库、Git-hooks、Nginx。三、 本地计算机与服务端建立通道，实现hexo上传。四、本地计算机渲染博客并部署到服务器。 一、本地计算机配置Hexo程序Note: 本地计算机为Deepin系统，理论上适用Ubuntu、Debian hexo需要node.js的支持，所以第一步是安装nodejs 打开终端窗口，根据系统输入以下命令之一：其他nodejs版本请参考Node.js Binary Distributionsnpm会随nodejs一起安装成功。 1234567# Using Ubuntucurl -sL https://deb.nodesource.com/setup_lts.x | sudo -E bash -sudo apt-get install -y nodejs# Using Debian, as rootcurl -sL https://deb.nodesource.com/setup_lts.x | bash -apt-get install -y nodejs 验证是否安装成功： 1234# node -v返回 v12.18.3node -v# npm -v返回 6.14.6npm -v 2. 初始化Hexo博客 安装Hexo选择目录存放本地hexo博客内容（假设主目录/home/xxx/），运行1npm install -g hexo-cli 初始化hexo：1hexo init blog # blog可以是其他任何你想起的名字 安装hexo其他插件：1234cd blognpm install #这个操作功能是补全依赖环境npm install hexo-deployer-git --save # 自动部署到服务器需要的插件npm install hexo-server # 本地简单的服务器，可以测试hexo是否安装成功 测试hexo是否安装成功。执行如下命令：1hexo g &amp;&amp; hexo server 然后访问localhost:4000，如果能看到hexo界面说明本地hexo安装成功。二、服务端配置网站根目录、Git裸仓库、Git-hooks、Git上传用户、Nginx。 配置网站根目录备用 指定一个目录，假设主目录/home/xxx/，创建文件夹hexo12cd /home/xxxmkdir hexo 服务端配置Git裸仓库 指定一个目录创建git裸仓库，可以选择/var/repo/。执行：1sudo git init --bare blog.git 配置git-hooks 切换到hooks文件夹1cd /var/repo/blog.git/hooks 创建文件post-receive，执行vim post-receive，进入vim在insert模式下输入：12# !/bin/shgit --work-tree=/home/xxx/hexo --git-dir=/var/repo/blog.git checkout -f 然后:wq保存 配置Nginx 安装Nginx： 1sudo apt-get install nginx 配置Nginx.conf：Nginx.conf位置是/etc/nginx/nginx.conf（也可能是/user/local/nginx/conf，可以whereis nginx命令查看具体位置）。编辑该文件内容，修改user、server12345678910111213user root;....http &#123; server &#123; listen 80; # 监听端口 server_name &quot;your url or ip&quot;; # 域名或者ip地址 location / &#123; root /home/xxx/hexo; # 服务端网站根目录 index index.html; &#125; &#125;&#125; 然后保存。三、本地计算机与服务端建立通道，实现hexo上传。 服务端创建并配置git用户，专门用于博客上传。 创建git用户，并更改git仓库的所有者12sudo adduser git # 创建用户sudo chown -R git:git /var/repo/blog.git 禁用 git 用户的 shell 登录权限出于安全考虑，我们要让 git 用户不能通过 shell 登录。可以编辑 /etc/passwd 来实现将git:x:1001:1001:,,,:/home/git:/bin/bash改成git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell这样 git 用户可以通过 ssh 正常使用 git，但是无法登录 shell。可以在服务端试一下，su git无法切换到git用户，报错fatal: Interactive git shell is not enabled.为什么非得搞一个新的git用户，我感觉原因出在这里，如果直接使用服务端原来的用户远程上传博客也行，只是存在安全问题。 本地计算机与服务端建立ssh通道。 本地计算机执行：1ssh-keygen 一直回车即可。这一步操作会在/home/xxx/.ssh/下生成两个文件id_rsa和id_rsa.pub。 服务端在/home/git目录下创建文件夹.ssh，并在/home/git/.ssh下创建文件authorized_keys。把id_rsa.pub的内容复制到服务端的authorized_keys中。注意是把本地计算机的/home/xxx/.ssh/id_rsa.pub复制到服务端的/home/git/.sshauthorized_keys。 本地计算机配置hexo deploy。 编辑/home/xxx/blog/_config.yml，配置deploy：1234deploy: type: git repo: git@&quot;your url or ip&quot;:/var/repo/blog.git branch: master 保存。四、本地计算机渲染博客并部署到服务器。 编写博客 方式一：创建博客使用的markdown文件，然后书写内容1hexo new &quot;xxxx&quot; 创建成功后，该markdown文件在source/_posts目录下。继续编辑xxx.md即可。 方式二：直接把写好了的md文件丢进source/_posts目录下。 渲染博客：1hexo gernerate 或者1hexo g 部署博客到服务器1hexo deploy 或者1hexo d 第二步和第三步可以一起使用1hexo g &amp;&amp; hexo d 或者1hexo g -d 或者1hexo d -g 操作完成后，服务端目录/home/deepin/hexo下会有刚刚提交的博客，但/var/repo/blog.git/branches不会有博客文件，因为它是裸仓库。 注意：hexo d可能会报错Error: EACCES: permission denied, unlink ...，说什么权限拒绝。如果使用sudo hexo d，就会报另外一种错误：git@github.com: Permission denied (publickey). fatal: 无法读取远程仓库。。解决办法：一劳永逸，直接chmod -R 777 blog/。参考博客：使用Hexo+Github搭建博客的各种问题 完工。整个流程请照文章开头的架构图理解一下，比较难理解的是第二章节和第三章节。 其他发现：hexo官网文档的一键部署，支持除了Git上传的其他部署方式，包括SFTP、RSync，逻辑应该是直接远程传输到服务端制定文件夹，配置相对简单，直接配置_config.yml的deploy属性即可。 有时间试一下。","categories":[{"name":"工具技巧","slug":"工具技巧","permalink":"119.3.128.89/categories/%E5%B7%A5%E5%85%B7%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"119.3.128.89/tags/hexo/"}]}],"categories":[{"name":"SQL","slug":"SQL","permalink":"119.3.128.89/categories/SQL/"},{"name":"算法题目","slug":"算法题目","permalink":"119.3.128.89/categories/%E7%AE%97%E6%B3%95%E9%A2%98%E7%9B%AE/"},{"name":"工具技巧","slug":"工具技巧","permalink":"119.3.128.89/categories/%E5%B7%A5%E5%85%B7%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"119.3.128.89/tags/SQL/"},{"name":"LeetCode","slug":"LeetCode","permalink":"119.3.128.89/tags/LeetCode/"},{"name":"hexo","slug":"hexo","permalink":"119.3.128.89/tags/hexo/"}]}